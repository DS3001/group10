{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqy14K6115IBwixYXkC7T7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DS3001/group10/blob/main/Project2_With_Paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project 2:\n",
        "Betsy Altenburger, Autumn Boaz, Olivia Byram, Olivia Yang, Alex Yang**"
      ],
      "metadata": {
        "id": "RPPOpdm2VauJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**"
      ],
      "metadata": {
        "id": "3Kr3BYGAVUQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, our primary goal was to create an effective model that could predict whether a person has a stroke, using a provided dataset that contained both qualitative and quantitative traits of that individual. To define an effective model, we aimed to achieve the lowest root mean square error (RMSE) possible for the testing data. Given a simple linear model that contained some polynomials and dummy variables, we utilized its R2 of 0.087 and RMSE of 0.206 as reference for our model. To begin, our group individually created models based on our own observations and strategies and then combined different aspects of each model to create our final one. The purpose of this was to see if utilizing diverse perspectives on the approach to the question, then working together to combine our ideas, was overall more effective than an individual model. The individual models were a combination of linear regression, regression/classification trees, k-nearest neighbor, and polynomial expansions. We chose the models with the lowest RMSE  then used context from them to decide which variables and expansions to use in our final ‘supermodel’. The data had been cleaned from the previous individual models, we converted most of the variables into dummy variables for simplicity. We also ensured that we removed any NaN’s that would cause skewed data distributions and replaced them with the mean. Our final model gave us an R-squared of 0.3073985097636177 and RMSE of 0.17943514064131835. This model was the k-nearest neighbor classification model with no polynomial expansion."
      ],
      "metadata": {
        "id": "fTr_-IFtVWZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data**"
      ],
      "metadata": {
        "id": "m_YhbDynVofK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*For the sake of this ipynb not being extremely long, we did not include the data cleaning for every single model we created. If you would like to see those, they are included in the folder. For example, Autumn's data cleaning is included with her model code in the project 2 folder under \"ABoaz_ModelFP\". The data cleaning for the final, combined model is included in the results section.*"
      ],
      "metadata": {
        "id": "gaP_sjJUXb6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that there were different models combined to develop a final model with the lowest RMSE value, there were a few different approaches to reading, cleaning, and preparing the data. The first step for all models was to use the “.head()” function to take a look at all of the variables in the data step. Unnecessary columns were removed, specifically ‘Unnamed: 0’ and “id”.  From there, the “isna().sum()” function was utilized to see how many na values were in each variable and the “.fillna()” function was used to replace the missing values with the average value of the column--this method was used for ‘bmi’."
      ],
      "metadata": {
        "id": "jiGbqOVMVqGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first approach, we mapped phrases from categorical variables to a numerical form. Specifically, using the “.replace()” function, the variables ‘ever_married’, ‘gender’, ‘smoking_status’, ‘Residence_type’, and ‘work_type’ were transformed to have numerical values that correlated with the original categories. For example, for ‘smoking_status’, the values were converted as follows: {\"never smoked\":0, \"formerly smoked\":1, \"smokes\":2, \"Unknown\":3}. Depending on the model created, other variables may have been dropped or changed, but they will be discussed further in the results section.\n"
      ],
      "metadata": {
        "id": "C8G63Bm-XAvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second approach utilized a windorizing function to account for the skew of data in certain variables, so the data preparation process was slightly different. Using a scatter plot to look at the spread of data and notice which variables had outliers, the ‘avg_glucose_level’ had the greatest number of outliers with ‘bmi’ following in the trend. Both variables were first converted to the integer type before further analysis proceeded."
      ],
      "metadata": {
        "id": "234B02lvXBfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even after windorizing ‘avg_glucose_level’, this variable was much larger than the other variables. The best way to deal with this is to take the inverse hyperbolic sine of ‘avg_glucose_level’ and save this variable as ‘avg_glucose_level_ihs’.\n",
        "\n",
        "The remaining cleaned variables were then sectioned into training and testing sets to be used in the model, named respectively as ‘X_train’, ‘y_train’, ‘X_test’, and ‘y_test’.\n"
      ],
      "metadata": {
        "id": "g4_xHuqbXB0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the overall model which was a combination of all the data cleaning tools each group member used, we used all of these data wrangling tactics discussed above. Windorizing was only used by one group member, but the other models from other group members ran with the winsorized data they performed better. This showed that our idea of separate model building to achieve the lowest RMSE was a good approach."
      ],
      "metadata": {
        "id": "Ag6Jb8yeXJSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**"
      ],
      "metadata": {
        "id": "4H4PPoTbXMfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Again, in the interest of not making this file too large, we decided to only include the code for our combine model. The code for the other models is included in the project 2 folder.*"
      ],
      "metadata": {
        "id": "Bz79Nhu9XOfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin constructing the model, all necessary packages were first imported. From the data preparation, the variables were fitted to a basic linear model using the “LinearRegression().fit()” function and predictions were made for the test data using “reg.predict()”. The base R2 was found to be 0.188, using the “reg.score()” function and the base RMSE was 0.194."
      ],
      "metadata": {
        "id": "vU3gRT9dXegt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For one of the approaches, a linear regression model utilizing expanded polynomials was created. The function “poly_expand” was created for the expander process, taking an input of ‘dat’ and expanding it to have polynomial features up to a specified degree of ‘deg’. The resulting features were then stored in the DataFrame ‘zdf’ and returned. From there, the function ‘lin_reg’ was created for the regression, using similar steps to the basic linear model from above. ‘Lin_reg’ took the parameters of ‘X_train’, ‘y_train’, ‘X_test’, and ‘y_test’. Utilizing scikit-learn’s ‘LinearRegression’ class, the function trains a linear regression model utilizing the provided training data which was then used to predict the target values ‘y_hat’ for the test data. The function also calculated and returned R2 and the RMSE value. The linear regression model was then run with a degree of 2 and then , using “poly_expand” to expand the “X_train” and “X_test” sets. The outputs had an R2 of 0.078 and RMSE of 0.207 for both degrees of 2 and 3."
      ],
      "metadata": {
        "id": "LF3tjp3nXhA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon applying the windsorizing function to the simple linear model that was provided, the  R2 had a slight increase of 0.088 though the RMSE remained 0.206. When applying this function to the linear regression model that contained polynomial features, the R2 value decreased to 0.077 and had an RMSE of 0.207, indicating that accounting for the outliers in the ‘avg_glucose_level’ and ‘bmi’ would not improve the predictive power of our linear regression model.\n"
      ],
      "metadata": {
        "id": "sCjWn6wmXjut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the next approach, a classification decision tree was created. To do this, a decision tree classifier with a maximum depth of 5 was instantiated and trained using ‘X_train’ and ‘y_train’ datasets and visualized with scikit-learn’s ‘tree.plot_tree’. Once the model was trained, predictions were created using the test set ‘X_test’ and the residuals were calculated. Using a kernel density plot, we visualized the distribution of the residuals. A scatter plot was also created to compare predicted and true values. The findings showed that there was 0 variance for the dataset using this model and that the classification decision tree was not the best model to use for predictions."
      ],
      "metadata": {
        "id": "gwmPBqovXmlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From there, a k-nearest neighbor (KNN) regression model was utilized and evaluated for its predictive power. The input data was first normalized using a max-min normalization function that scaled the ‘X_train’ and ‘X_test’ datasets. The code was then iterated over a range of k to find the optimal k value. The sum of squared training errors were stored as ‘SSE’ and the lowest value was stored as ‘SSE_min’."
      ],
      "metadata": {
        "id": "8JZWqF7RXp2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A k-mean-cluster (KMC) model was also utilized for variables ‘smoking_status’, ‘residence_type’, ‘hypertension’, and ‘heart_disease’. The input data was first evaluated and cleaned using the same methods as described in the data preparation section. Then, the data was normalized by maxmin function. A Scree Plot was created to determine the optimal number of k to use which end up being 7. After this step, a KMC model was fitted and evaluated, a pairplot was also created. This model was not included in the final combined model because of its high RMSE value."
      ],
      "metadata": {
        "id": "2qGnNiK4XsZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THIS IS WHERE WE PUT COMBINED MODEL RESULTS**"
      ],
      "metadata": {
        "id": "dBVfkaKYXwp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/DS3001/group10/"
      ],
      "metadata": {
        "id": "c8JWPPN_XzB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "metadata": {
        "id": "AyvPz9b3YLL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"./group10/project_2/data/training_data.csv\")\n",
        "df_test = pd.read_csv(\"./group10/project_2/data/testing_data.csv\")"
      ],
      "metadata": {
        "id": "gNVcwSfVYMrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the test and train X and Y variables\n",
        "y_train = df_train['stroke']\n",
        "X_train = df_train.drop(columns = ['stroke'],axis=1)\n",
        "y_test = df_test['stroke']\n",
        "X_test = df_test.drop(columns = ['stroke'],axis=1)"
      ],
      "metadata": {
        "id": "qDg7QJyCYP08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "\n",
        "# We filled in the BMI NaN values with the mean\n",
        "X_train['bmi'] = X_train['bmi'].fillna(X_train['bmi'].mean())\n",
        "X_test['bmi'] = X_test['bmi'].fillna(X_test['bmi'].mean())\n",
        "\n",
        "\n",
        "# Mapped all the string values to numerical values\n",
        "X_train['ever_married'] = X_train['ever_married'].replace({\"No\":0, \"Yes\":1})\n",
        "X_test['ever_married'] = X_test['ever_married'].replace({\"No\":0, \"Yes\":1})\n",
        "\n",
        "X_train['gender'] = X_train['gender'].replace({\"Male\":0, \"Female\":1, \"Other\":2})\n",
        "X_test['gender'] = X_test['gender'].replace({\"Male\":0, \"Female\":1, \"Other\":2})\n",
        "\n",
        "X_train['smoking_status'] = X_train['smoking_status'].replace({\"never smoked\":0, \"formerly smoked\":1, \"smokes\":2,\n",
        "                                                          \"Unknown\":3})\n",
        "X_test['smoking_status'] = X_test['smoking_status'].replace({\"never smoked\":0, \"formerly smoked\":1, \"smokes\":2,\n",
        "                                                          \"Unknown\":3})\n",
        "\n",
        "X_train['Residence_type'] = X_train['Residence_type'].replace({\"Urban\":0, \"Rural\":1})\n",
        "X_test['Residence_type'] = X_test['Residence_type'].replace({\"Urban\":0, \"Rural\":1})\n",
        "\n",
        "X_train['work_type'] = X_train['work_type'].replace({\"Private\":0, \"Self-employed\":1, \"children\":2,\n",
        "                                                          \"Govt_job\":3, \"Never_worked\":4})\n",
        "X_test['work_type'] = X_test['work_type'].replace({\"Private\":0, \"Self-employed\":1, \"children\":2,\n",
        "                                                          \"Govt_job\":3, \"Never_worked\":4})"
      ],
      "metadata": {
        "id": "5DEcSyGDYR4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one group member windsorized and it worked well so we implemented this for all the models\n",
        "def windsorize(x):\n",
        "    # Compute IQR and 1st,3rd quantiles\n",
        "    pct25, pct75 = np.percentile(x, [25, 75])\n",
        "    iqr = pct75 - pct25\n",
        "    # Compute whiskers:\n",
        "    lower_whisker = pct25 - iqr * 1.5\n",
        "    upper_whisker = pct75 + iqr * 1.5\n",
        "    # Windsorize x:\n",
        "    x_windsor = x\n",
        "    x_windsor[x < lower_whisker] = lower_whisker\n",
        "    x_windsor[x > upper_whisker] = upper_whisker\n",
        "    return x_windsor\n",
        "\n",
        "df_train['avg_glucose_level'] = windsorize(df_train['avg_glucose_level'])\n",
        "df_train['bmi'] = windsorize(df_train['bmi'])\n",
        "\n",
        "df_test['avg_glucose_level'] = windsorize(df_test['avg_glucose_level'])\n",
        "df_test['bmi'] = windsorize(df_test['bmi'])\n",
        "\n",
        "\n",
        "df_train.plot.box()"
      ],
      "metadata": {
        "id": "0Z4jEZCUYUSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another group member took the inverse hyperbolic sin of average glucose level\n",
        "X_train['avg_glucose_level_ihs'] = np.arcsinh(X_train['avg_glucose_level'])\n",
        "X_test['avg_glucose_level_ihs'] = np.arcsinh(X_test['avg_glucose_level'])\n",
        ""
      ],
      "metadata": {
        "id": "Y140IVtJYWdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic linear model with no variable expansion only the changes made above\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "y_hat = reg.predict(X_test)\n",
        "\n",
        "#calculating r-squared\n",
        "rsqu = reg.score(X_test, y_test)\n",
        "print(\"R-Squared: \", rsqu )\n",
        "N = len(y_test)\n",
        "print('RMSE: ', (np.sum( (y_test - y_hat)**2)/N )**.5 )"
      ],
      "metadata": {
        "id": "aYM4IyU5YYzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_hat\n",
        "sns.kdeplot(residuals)\n",
        "plt.title(\"Residuals for Linear Regression\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x=y_hat,y=y_test)\n",
        "plt.title('Predicted vs. Actual Values for Linear Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WQjggvUIYart"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now this is a linear model with polynomial expansion\n",
        "# We found that degree 2 gave the best results\n",
        "\n",
        "X_train_numeric = X_train.loc[:,['age','hypertension','heart_disease','bmi','avg_glucose_level_ihs'] ]\n",
        "\n",
        "expander = PolynomialFeatures(degree=2,include_bias=False) # Create the expander\n",
        "Z = expander.fit_transform(X_train_numeric) # Pass the df into the expander to get powers/interactions of x and y\n",
        "names = expander.get_feature_names_out() # Get the names of these variables\n",
        "continuous = pd.DataFrame(data=Z, columns = names) # Create a new, expanded dataframe\n",
        "\n",
        "dummies = pd.concat([ pd.get_dummies(X_train['work_type'],dtype='int',drop_first=True),\n",
        "                      pd.get_dummies(X_train['Residence_type'],dtype='int',drop_first=True),\n",
        "                      pd.get_dummies(X_train['smoking_status'],dtype='int',drop_first=True)],axis=1)\n",
        "\n",
        "Z_train = pd.concat([continuous,dummies],axis=1)\n",
        "Z_train.columns = Z_train.columns.astype(str)\n",
        "X_test_numeric = X_test.loc[:,['age','hypertension','heart_disease','bmi','avg_glucose_level_ihs'] ]\n",
        "\n",
        "expander = PolynomialFeatures(degree=2,include_bias=False) # Create the expander\n",
        "Z = expander.fit_transform(X_test_numeric) # Pass the df into the expander to get powers/interactions of x and y\n",
        "names = expander.get_feature_names_out() # Get the names of these variables\n",
        "continuous = pd.DataFrame(data=Z, columns = names) # Create a new, expanded dataframe\n",
        "\n",
        "dummies = pd.concat([ pd.get_dummies(X_test['work_type'],dtype='int',drop_first=True),\n",
        "                      pd.get_dummies(X_test['Residence_type'],dtype='int',drop_first=True),\n",
        "                      pd.get_dummies(X_test['smoking_status'],dtype='int',drop_first=True)],axis=1)\n",
        "\n",
        "Z_test = pd.concat([continuous,dummies],axis=1)\n",
        "Z_test.columns = Z_test.columns.astype(str)\n",
        "# Fit the model and get the R2 measure:\n",
        "reg = LinearRegression().fit(Z_train, y_train) # Fit the linear model\n",
        "print('R2: ', reg.score(Z_test, y_test)) # R squared measure\n",
        "y_hat = reg.predict(Z_test)\n",
        "N = len(y_test)\n",
        "\n",
        "print('RMSE: ', (np.sum( (y_test - y_hat)**2)/N )**.5 )"
      ],
      "metadata": {
        "id": "CPECERIoYcdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes the residuals and plots the curve\n",
        "residuals = y_test - y_hat\n",
        "sns.kdeplot(residuals)\n",
        "plt.title(\"Residuals for Expanded Linear Regression\")\n",
        "plt.show()\n",
        "\n",
        "# this plot shows the difference between predicted and actual values\n",
        "plt.scatter(x=y_hat,y=y_test)\n",
        "plt.title('Predicted vs. Actual Values for Expanded Linear Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HXsD1GjBYiuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the KNeighborsClassifer model with 9 neighbors\n",
        "model = KNeighborsClassifier(n_neighbors=9)\n",
        "fitted_model = model.fit(X_train,y_train)\n",
        "y_hat = fitted_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ZXRqJ_v_Ymtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_squared = model.score(X_test, y_test)\n",
        "print(f'R-squared: {r_squared}')\n",
        "\n",
        "# Calculate RMSE\n",
        "y_hat = model.predict(X_test)\n",
        "N = len(y_test)\n",
        "print('RMSE: ', (np.sum( (y_test - y_hat)**2)/N )**.5 )"
      ],
      "metadata": {
        "id": "63lgo42eYoqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_hat\n",
        "sns.kdeplot(residuals)\n",
        "plt.title(\"Residuals for KNeighbors Classification\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x=y_hat,y=y_test)\n",
        "plt.title('Predicted vs. Actual Values for KNeighbors Classification')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hUe84LSaYqrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, the best model KNeighbors regressor.\n",
        "# Maxmin normalization function:\n",
        "def maxmin(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return(z)\n",
        "\n",
        "# Apply maxmin to each column of X:\n",
        "X_train_knn = X_train.apply(maxmin)\n",
        "X_test_knn = X_test.apply(maxmin)\n",
        "\n",
        "# Determine optimal k:\n",
        "k_bar = 70\n",
        "k_grid = np.arange(1,k_bar) # The range of k's to consider\n",
        "SSE = np.zeros(k_bar-1) # For comparison purposes, store the training error\n",
        "for k in range(k_bar-1):\n",
        "    model = KNeighborsRegressor(n_neighbors=k+1) # Create a sk model for k\n",
        "    fitted_model = model.fit(X_train_knn,y_train) # Train the model on our data\n",
        "    y_hat = fitted_model.predict(X_test_knn) # Predict values for test set\n",
        "    SSE[k] = np.sum( (y_test-y_hat)**2 ) # Save the computed SSE\n",
        "SSE_min = np.min(SSE) # Lowest recorded SSE\n",
        "min_index = np.where(SSE==SSE_min) # Find the indices of y that equal the minimum\n",
        "k_star = k_grid[min_index][0] # Find the optimal value of k\n",
        "\n",
        "## SSE plot:\n",
        "plt.plot(k_grid,SSE)\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.title('SSE')\n",
        "plt.show()\n",
        "# The plot shows that the best values for k is 3!\n",
        "\n",
        "## Fit optimal model:\n",
        "model = KNeighborsRegressor(n_neighbors=max(3,k_star))\n",
        "knn_star = model.fit(X_train_knn,y_train)\n",
        "y_hat_knn = knn_star.predict(X_test_knn)\n",
        "residuals_knn = y_test - y_hat_knn"
      ],
      "metadata": {
        "id": "6YBOcKKwYtuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TSS = np.sum( (y_test - y_test.mean())**2 )\n",
        "SSE_knn = np.sum( (y_test-y_hat_knn)**2 )\n",
        "MSE_knn = SSE_knn/N\n",
        "RMSE_knn = (SSE_knn/N)**(1/2)\n",
        "R2_knn = 1 - SSE_knn/TSS\n",
        "print(\"R^2:\", R2_knn)\n",
        "print(\"RMSE:\", RMSE_knn)"
      ],
      "metadata": {
        "id": "mjHw8pZLYvXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals_knn = y_test - y_hat_knn\n",
        "sns.kdeplot(residuals_knn)\n",
        "plt.title(\"Residuals for KNeighbors Regression\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x=y_hat_knn,y=y_test)\n",
        "plt.title('Predicted vs. Actual Values for KNeighbors Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zg8oUdBbYzAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**"
      ],
      "metadata": {
        "id": "FyTB_QBYY92Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we attempted to approach this problem through a variety of perspectives, rather than agreeing on one method and attempting it once. Throughout this class, we have learned that it is important to examine data from multiple angles, especially when it is sensitive information such as predicting strokes. Somebody may see a variable as useless, while another person might see it as the most significant one. Our approach towards creating the best possible model followed basic rules - get multiple opinions, and do not be afraid to create a model that fails. As you could tell from some of our models, we did not achieve a lower RMSE and higher R-squared than a basic linear model. This was a part of our process, figuring out what worked, and adapting to create a better model on our next attempt."
      ],
      "metadata": {
        "id": "4FT1QsAvY_cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our individual models included expanded linear regression models, k-means clustering models, and classification tree models. For a linear regression model with expanded polynomials, both degrees of 2 and 3, the outputs had an R2 of 0.078 and RMSE of 0.207. This was not better than the base linear regression model. When accounting for outliers, the R-squared decreased further, while the RMSE increased. This indicated that accounting for outliers was not going to help us create a better model. The next model, the classification tree, was proven to dramatically overfit the data. This gave us evidence that the classification tree was not useful, and we chose to move to the next individual model. K-means clustering did not perform better than any of the other models, with an R-squared of -119. Due to none of our models being better than the basic linear regression model on its own, we chose to combine the models (as we figured it couldn’t get worse). Our final model gave us an R-squared of 0.3073985097636177 and RMSE of 0.17943514064131835. This model was the k-nearest neighbor classification model with no polynomial expansion."
      ],
      "metadata": {
        "id": "NiqcCVttZCLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The varied and diverse approach to the way we created our final model is the reason that we are confident in its ability, and safe from criticism. By getting several outlooks on what the best model would be, we tested virtually every method that we learned in this class. This allowed us to see the data from multiple angles, which prevents mistakes that pertain to close-mindedness and oversight. In addition, we all individually cleaned the data, then chose which variables would be best to use. Again, having multiple people clean the data prevents oversight and data cleaning errors. We are confident that we were able to remove the NaNs and successfully convert our variables into dummy variables. While critics may be worried that we did not arrive at the correct results, due to many of our models failing, we agree to disagree. We were able to learn from our failures, and argue that a model failing provides just as much information as a model that succeeds."
      ],
      "metadata": {
        "id": "k62LbXEiZE9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we had the time, and motivation, we would have loved to use ensemble methods on our supermodel and see how good of a fit we could come up with. Particularly, we are interested in the effect that bagging would have had. We could have used bagging to combine all of our models into one mega-model, instead of picking and choosing parts of different individual models. It would be very interesting to see if these methods could save our model from being worse than basic linear regression - especially since in a real world scenario these methods would likely be used."
      ],
      "metadata": {
        "id": "D0P2rEltZH54"
      }
    }
  ]
}